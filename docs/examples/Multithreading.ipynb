{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple DSS engines, multithreading vs. multiprocessing\n",
    "\n",
    "*Parallel OpenDSS/AltDSS engines in the same process*\n",
    "\n",
    "<!-- TODO: update link to the website when ready -->\n",
    "[General recommendations apply](https://github.com/dss-extensions/dss-extensions/blob/main/docs/multithreading.md), like using a good memory allocator on Linux.\n",
    "\n",
    "For a similar example using OpenDSSDirect.py (the `_run` function is what changes): https://dss-extensions.org/opendssdirect.py/notebooks/Multithreading.html\n",
    "\n",
    "If you need to create multiple, independent OpenDSS engines, [DSS.NewContext()](https://dss-extensions.org/dss_python/apidocs/dss/dss.IDSS.html#dss.IDSS.IDSS.NewContext) can be used.\n",
    "This was introduced in DSS-Python 0.12.0, after a lot of work in the underlying DSS C-API engine. This feature is also unique to DSS-Extensions. \n",
    "\n",
    "Although multi-threading in Python is not great due to the the GIL (Global Interpreter Lock), it is important to note that DSS-Python releases when API calls are made, i.e. multiple Python threads that spend most time in power flow solutions should still be performant.\n",
    "\n",
    "Check other DSS-Extensions for implementations of multi-threading using multiple DSS contexts in\n",
    "other programming languages:\n",
    "\n",
    "- [OpenDSSDirect.jl](https://github.com/dss-extensions/OpenDSSDirect.jl/blob/master/test/ctx_threads.jl)\n",
    "- [dss.hpp](https://dss-extensions.org/dss_capi/)\n",
    "- [DSS Sharp](https://dss-extensions.org/dss_sharp/)\n",
    "- [AltDSS-Rust](https://github.com/dss-extensions/AltDSS-Rust)\n",
    "\n",
    "If you are not comfortable with threads, we recommend using Python's [multiprocessing](https://docs.python.org/3/library/multiprocessing.html), especially for larger circuits. `multiprocessing` can be used with most OpenDSS implementations. We also provide a [basic example here](https://sourceforge.net/p/electricdss/discussion/861976/thread/5703a79b3b/?limit=25#4dbf) in the OpenDSS forum, besides the example in this document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "\n",
    "from dss import dss, IDSS # IDSS for type hints and better autocomplete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NUM_SOLVE` below is used as the number of solution for each scenario. Read more at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SOLVE = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that OpenDSS changes the working directory of the process? To use multiple instances, we need to disable that behavior. When disabled, the AltDSS engine will track the required paths without changing the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.AllowChangeDir = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually don't want the editor popping up and/or interrupting this kind of batch run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.AllowForms = False\n",
    "dss.AllowEditor = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's provide some circuits to run. Remember to adjust `BASE_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './electricdss-tst'\n",
    "fns = [\n",
    "    f\"{BASE_DIR}/Version8/Distrib/EPRITestCircuits/epri_dpv/M1/Master_NoPV.dss\",\n",
    "    f\"{BASE_DIR}/Version8/Distrib/EPRITestCircuits/epri_dpv/K1/Master_NoPV.dss\",\n",
    "    f\"{BASE_DIR}/Version8/Distrib/EPRITestCircuits/epri_dpv/J1/Master_withPV.dss\",\n",
    "    f\"{BASE_DIR}/Version8/Distrib/IEEETestCases/8500-Node/Master-unbal.dss\",\n",
    "    f\"{BASE_DIR}/Version8/Distrib/IEEETestCases/NEVTestCase/NEVMASTER.DSS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble a list of all scenarios to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = []\n",
    "for fn in fns:\n",
    "    for load_mult in (0.9, 0.95, 1.0, 1.05, 1.1):\n",
    "        cases.append((fn, load_mult))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide how many instances based on the number of cases and the CPU count. For processors with Hyper-threading, it might be best to run with the number of real cores. It all depends on the processor architecture, such as cache and memory bandwidth, and the characteristics of the DSS circuit being used. It is recommended to run a few tests to select the optional number of threads, especially for large scale circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 25 DSS contexts\n"
     ]
    }
   ],
   "source": [
    "# Use the number of threads as CPU count, number of cases\n",
    "num = min(len(cases), os.cpu_count())\n",
    "\n",
    "# Initialize a new context for each of the threads\n",
    "ctxs = [dss.NewContext() for n in range(num)]\n",
    "print(f\"Using {len(ctxs)} DSS contexts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dicts to keep the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresults = {}\n",
    "tconverged = {}\n",
    "sresults = {}\n",
    "sconverged = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the worker function that will run the workload, both in the threads and sequentially.\n",
    "\n",
    "Note that it references some structures shared as input to the function. Since there is a GIL, we don't need to use locks. You may need to adjust that for more general usage.\n",
    "\n",
    "Uncomment the `print` calls for some visual feedback while running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run(ctx: IDSS, case_list, converged, results):\n",
    "    tname = threading.current_thread().name\n",
    "    circ = ctx.ActiveCircuit\n",
    "    while case_list:\n",
    "        fn, load_mult = case_list.pop()\n",
    "        ctx('clear')\n",
    "        try:\n",
    "            ctx(f'redirect \"{fn}\"')\n",
    "            circ.Solution.LoadMult = load_mult\n",
    "            # print(f'{tname}: Running \"{fn}\", circuit \"{ctx.ActiveCircuit.Name}\", mult={load_mult}')\n",
    "            ctx(f'Solve mode=daily number={NUM_SOLVE}')\n",
    "        except Exception as ex:\n",
    "            print('ERROR:', tname, (fn, load_mult))\n",
    "            print('      ', ex.args)\n",
    "\n",
    "        # print(f'{tname}: Done \"{fn}\" (LoadMult={load_mult}), circuit \"{circ.Name}\"')\n",
    "        converged[(fn, load_mult)] = circ.Solution.Converged\n",
    "        # Just get the voltages to compare later; an actual study could get other\n",
    "        # useful values or calculate specific indices for each scenario\n",
    "        results[(fn, load_mult)] = circ.AllBusVolts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreaded run\n",
    "\n",
    "With all in place, let's create and run the threads until completion.\n",
    "\n",
    "The threads will consume input scenarios from `cases_to_run_threads`, outputting to `tconverged` and `tresults`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.714 s with 25 threads\n"
     ]
    }
   ],
   "source": [
    "# Copy the list of scenarios\n",
    "cases_to_run_threads = list(cases)\n",
    "\n",
    "t0 = perf_counter()\n",
    "threads = []\n",
    "for ctx in ctxs:\n",
    "    t = threading.Thread(target=_run, args=(ctx, cases_to_run_threads, tconverged, tresults))\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "t1 = perf_counter()\n",
    "\n",
    "# Check if all solutions converged\n",
    "assert all(tconverged.values())\n",
    "\n",
    "dt_thread = (t1 - t0)\n",
    "print(f'Done in {dt_thread:.3f} s with {num} threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-threaded / sequential run\n",
    "\n",
    "For a comparison, let's also run the same cases sequentially in a simple thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 4.242 s sequentially\n"
     ]
    }
   ],
   "source": [
    "# Copy the list of scenarios\n",
    "cases_to_run_seq = list(cases)\n",
    "\n",
    "t0 = perf_counter()\n",
    "\n",
    "_run(dss, cases_to_run_seq, sconverged, sresults)\n",
    "\n",
    "t1 = perf_counter()\n",
    "dt_seq = (t1 - t0)\n",
    "print(f'Done in {dt_seq:.3f} s sequentially')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the results\n",
    "\n",
    "Check if each scenario has the same results whether it ran in multiple threads or a single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    np.testing.assert_equal(sresults[case], tresults[case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! For modern processors, the difference of running in a single thread vs. multiple can be significant. \n",
    "\n",
    "Traditionally, a lot of OpenDSS users ran tasks in parallel with the `multiprocessing` module or other tools like Dask.Distributed, but depending on the use-case, multithreading can present interesting advantages, such as easier use of shared resources.\n",
    "\n",
    "For an approach compatible with the current official OpenDSS versions, using either `multiprocessing` or the `dss.Parallel` functions would be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `multiprocessing`\n",
    "\n",
    "For completeness, let's also run using the `multiprocessing` module, which is part of Python's standard library.\n",
    "\n",
    "Here, instead of modifying the structs directly, we have to keep in mind that the input data will be serialized, and so will the output data from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_mp(fn, load_mult):\n",
    "    from dss import dss as ctx\n",
    "    circ = ctx.ActiveCircuit\n",
    "    ctx('clear')\n",
    "    try:\n",
    "        ctx(f'redirect \"{fn}\"')\n",
    "        circ.Solution.LoadMult = load_mult\n",
    "        # print(f'Running \"{fn}\", circuit \"{ctx.ActiveCircuit.Name}\", mult={load_mult}')\n",
    "        ctx(f'Solve mode=daily number={NUM_SOLVE}')\n",
    "    except Exception as ex:\n",
    "        print('ERROR:', (fn, load_mult))\n",
    "        print('      ', ex.args)\n",
    "        \n",
    "    # print(f'Done \"{fn}\" (LoadMult={load_mult}), circuit \"{circ.Name}\"')\n",
    "    return (fn, load_mult, circ.Solution.Converged, circ.AllBusVolts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run using the same number workers as before. After running, assemble back the results in dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 1.131 s using 25 processes\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "t0 = perf_counter()\n",
    "pool = mp.Pool(processes=num)\n",
    "results_mp = pool.starmap(_run_mp, cases)\n",
    "\n",
    "# Assemble back the results\n",
    "mpresults = {(item[0], item[1]): item[3] for item in results_mp}\n",
    "mpconverged = {(item[0], item[1]): item[2] for item in results_mp}\n",
    "\n",
    "t1 = perf_counter()\n",
    "dt_mp = (t1 - t0)\n",
    "print(f'Done in {dt_mp:.3f} s using {num} processes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And validate the results, just to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    np.testing.assert_equal(sresults[case], mpresults[case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance notes\n",
    "\n",
    "If each task is short-lived, keeping the processes alive and reusing the engines is more efficient, but that's not the point of this example. Try rerunning this notebook setting `NUM_SOLVE=960` (or a larger number) vs. `NUM_SOLVE=96`. At some point, the task is long enough that it doesn't matter if processes or threads are used, since the overhead is diluted. That is also true when using/comparing the scenarios that can be run using the internal `Parallel` interface from OpenDSS.\n",
    "\n",
    "For shorter tasks and small circuits, threads should always win if most of the time is spent in the DSS engine, since that releases the Python GIL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Parallel`/PM implementation\n",
    "\n",
    "The DSS-Extensions implementation of the OpenDSS engine does include support for the parallel-machine (PM) concepts of the official implementation. The internals are completely different, and in fact result in a wider range of scenarios where it could be used when compared to the official version. Although useful in other use-cases like running through COM in Excel/VBA or MATLAB, using thread and multiple DSS engines explicitly provide more control. Sometimes threading is not ideal and using multiprocessing is preferred anyway, so there is little space where the PM alternative would be recommended with DSS-Python.\n",
    "\n",
    "For the `Parallel` interface and the parallel-machine commands from OpenDSS, check [the official documentation](https://opendss.epri.com/OpenDSSParallelProcessingSuite.html), and the [API docs for the interface](https://dss-extensions/apidocs/dss/dss.IParallel.html#dss.IParallel.IParallel) in DSS-Python.\n",
    "\n",
    "Currently, DSS-Extensions do not implement the diakoptics methods anymore. Due to limitations found in the past, the methods were disabled and will be reenabled after the developers on DSS-Extensions have an opportunity to address those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future expectations\n",
    "\n",
    "Specific to DSS-Extensions, there could be new features to enable automatic sharing of some data. Some of the required infrastructure is already in place, but there are tasks with higher priority before a system is fully implemented.\n",
    "\n",
    "There has been recent changes in Python and more are expected for Python 3.13 (expected by October 2024, first beta in May 2024) which would enable better performance when using multiple threads by using subinterpreters (see [PEP 734](https://peps.python.org/pep-0734/)). When the toolset is mature, the projects on DSS-Extensions will try to integrate it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
